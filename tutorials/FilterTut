###dDocent Filtering Tutorial###
###Designed by Jon Puritz###

###GOALS###
##	1.  To learn how to use VCFtools to filter a VCF file for missing data, genotype depth, locus quality score, minor allele frequency, and genotype call depth
##	2.	To learn how to use vcflib to filter FreeBayes VCF files generated with RAD data
##	3.	To filter a VCF file for HWE within populations
##	4.	How to decompose a VCF into SNPs and INDELs and
##	5.	How to use a haplotyping script to further filter SNPs for paralogs and genotyping errors.
###########

##	This file is executable.  Simply type FilterTut [Step_Number] to skip to different steps without opening the whole file.
## 	Command lines start with a "$"

#1	Welcome to the SNP filtering exercise.  For the first part of the exercise, the filtering steps should work on almost any VCF file.  
#1	For the second part of the exercise, we are going to assume you are working with a VCF file that was generated by
#1	FreeBayes.  Note that other SNP callers can be configured to include the same annotations.
#1	Let's find our way back to your original working directory and make a new filtering directory
#c#1	$mkdir filtering
#c#1	$cd filtering
#2
#2	Now, let's download some data to look at.  
#c#2	$curl -L -o data.zip https://www.dropbox.com/sh/bf9jxviaoq57s5v/AAD2Kv5SPpHlZ7LC7sBz4va8a?dl=1
#c#2	$unzip data.zip 
#c#3	$ll	
#3	total 165620
#3	-rwxr--r--. 1 jpuritz users   109633 Mar  6 14:56 BR_004-RG.bam
#3	-rwxr--r--. 1 jpuritz users   247496 Mar  6 14:57 BR_004-RG.bam.bai
#3	-rwxr--r--. 1 jpuritz users   120045 Mar  6 15:14 BR_006-RG.bam
#3	-rwxr--r--. 1 jpuritz users   247712 Mar  6 15:14 BR_006-RG.bam.bai
#3	-rw-r--r--. 1 jpuritz users 78979977 Mar  6 16:15 data.zip
#3	drwxr-xr-x. 2 jpuritz users       21 Mar  6 16:16 __MACOSX
#3	-rwxr--r--. 1 jpuritz users      399 Mar  6 15:08 popmap
#3	-rwxr--r--. 1 jpuritz users 68264393 Mar  6 13:40 raw.vcf.gz
#3	-rwxr--r--. 1 jpuritz users  6804314 Mar  6 14:49 reference.fasta
#3	-rwxr--r--. 1 jpuritz users  1085387 Mar  6 14:49 reference.fasta.amb
#3	-rwxr--r--. 1 jpuritz users  1068884 Mar  6 14:49 reference.fasta.ann
#3	-rwxr--r--. 1 jpuritz users  6379720 Mar  6 14:49 reference.fasta.bwt
#3	-rwxr--r--. 1 jpuritz users   353544 Mar  6 14:49 reference.fasta.clstr
#3	-rwxr--r--. 1 jpuritz users   976388 Mar  6 14:49 reference.fasta.fai
#3	-rwxr--r--. 1 jpuritz users  1594913 Mar  6 14:49 reference.fasta.pac
#3	-rwxr--r--. 1 jpuritz users  3189872 Mar  6 14:49 reference.fasta.sa
#3	-rwxr--r--. 1 jpuritz users   137209 Mar  6 14:30 stats.out
#4
#4	To start, we are going to use the program VCFtools (http://vcftools.sourceforge.net) to filter our vcf file.  This program has a binary executable
#4	and has several perl scripts as well that are useful for filtering. 
#4	I find it much more useful to use version 0.1.11, since it has more useful filtering commands (I think).  Let's load that version
#4	This raw.vcf file is going to have a lot of erroneous variant calls and a lot of variants that are only present in one individual.  
#4	To make this file more manageable.  Let's start by a three step filter.  We are going to only keep variants that have been successfully genotyped in 
#4	50% of individuals, a minimum quality score of 30, and a minor allele count of 3.
#c#4	$vcftools --gzvcf raw.vcf.gz --geno 0.5 --mac 3 --recode --recode-INFO-all --out raw.g5mac3
#4
#4	In this code, we call vcftools, feed it a vcf file after the --vcf flag, --geno 0.5 tells it to filter genotypes called below 50% (across all individuals)
#4	the --mac 3 flag tells it to filter SNPs that have a minor allele count less than 3.  
#4	This is relative to genotypes, so it has to be called in at least 1 homozygote and 1 heterozygote or 3 heterozygotes. 
#4	The --recode flag tells the program to write a new vcf file with the filters, --recode-INFO-all keeps all the INFO flags from the old vcf file in the new one.
#4	Lastly --out designates the name of the output
#4	The output will scroll through a lot of lines, but should end like:
#4	After filtering, kept 40 out of 40 Individuals
#4	After filtering, kept 78434 out of a possible 147540 Sites
#4	Outputting VCF file... Done
#4	Run Time = 40.00 seconds 
#4	Those two simple filters got rid of 50% of the data and will make the next filtering steps run much faster.
#5	
#5	We now have a filtered VCF called raw.g5mac3.recode.vcf.  There is also a logfile generated called raw.g5mac3.log
#5	The next filter we will apply is a minimum depth for a genotype call and a minimum mean depth
#c#5	$vcftools --vcf raw.g5mac3.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.g5mac3dp3 
#5	This command will recode genotypes that have less than 3 reads.
#5	I'll give you a second to take a deep breath.
#5	Yes, we are keeping genotypes with as few as 3 reads.  We talked about this in the lecture portion of this course, but the short answer is that
#5	sophisticated multisample variant callers like FreeBayes and GATK can confidently call genotypes with few reads because variants are assessed across all
#5	samples simultaneously.  So, the genotype is based on three reads AND prior information from all reads from all individuals.  Relax.  We will do plenty
#5	of other filtering steps!
#6	
#6	Don't believe me do you?  I've made a script to help evaluate the potential errors.
#c#6	$curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/ErrorCount.sh
#c#6	$chmod +x ErrorCount.sh 
#c#6	$ErrorCount.sh raw.g5mac3dp3.recode.vcf 
#6	This script counts the number of potential genotyping errors due to low read depth
#6	It report a low range, based on a 50% binomial probability of observing the second allele in a heterozygote and a high range based on a 25% probability.
#6	Potential genotyping errors from genotypes with only 1 read range from 0 to 0.0
#6	Potential genotyping errors from genotypes with only 2 reads range from 0 to 0.0
#6	Potential genotyping errors from genotypes with only 3 reads range from 15982 to 53700.36
#6	Potential genotyping errors from genotypes with only 4 reads range from 6230 to 31502.04
#6	Potential genotyping errors from genotypes with only 5 reads range from 2493 to 18914
#6	40 number of individuals and 78434 equals 3137360 total genotypes
#6	Total genotypes not counting missing data 2380094
#6	Total potential error rate is between 0.0103798421407 and 0.0437446588244
#6	
#6	
#6	
#6	SCORCHED EARTH SCENARIO
#6	WHAT IF ALL LOW DEPTH HOMOZYGOTE GENOTYPES ARE ERRORS?????
#6	The total SCORCHED EARTH error rate is 0.129135235835.
#6
#6	Right now, the maximum error rate for our VCF file because of genotypes less than 5 reads is less than 5%.  See, nothing to worry about.
#7
#7	The next step is to get rid of individuals that did not sequence well.  We can do this by assessing individual levels of missing data.
#c#7	$vcftools --vcf raw.g5mac3dp3.recode.vcf --missing
#7	This will create an output called out.imiss.  Let's examine it.
#c#8	$cat out.imiss
#8	
#8	INDV	N_DATA	N_GENOTYPES_FILTERED	N_MISS	F_MISS
#8	BR_002	78434	0	13063	0.166548
#8	BR_004	78434	0	16084	0.205064
#8	BR_006	78434	0	25029	0.319109
#8	BR_009	78434	0	30481	0.38862
#8	BR_013	78434	0	69317	0.883762
#8	BR_015	78434	0	8861	0.112974
#8	BR_016	78434	0	29789	0.379797
#8	BR_021	78434	0	17422	0.222123
#8	BR_023	78434	0	43913	0.559872
#8	BR_024	78434	0	24220	0.308795
#8	BR_025	78434	0	21998	0.280465
#8	BR_028	78434	0	26786	0.34151
#8	BR_030	78434	0	74724	0.952699
#8	BR_031	78434	0	26488	0.337711
#8	BR_040	78434	0	19492	0.248515
#8	BR_041	78434	0	17107	0.218107
#8	BR_043	78434	0	16384	0.208889
#8	BR_046	78434	0	28770	0.366805
#8	BR_047	78434	0	13258	0.169034
#8	BR_048	78434	0	24505	0.312428
#8	WL_031	78434	0	22566	0.287707
#8	WL_032	78434	0	22604	0.288191
#8	WL_054	78434	0	32902	0.419486
#8	WL_056	78434	0	34106	0.434837
#8	WL_057	78434	0	37556	0.478823
#8	WL_058	78434	0	31448	0.400949
#8	WL_061	78434	0	35671	0.45479
#8	WL_064	78434	0	47816	0.609634
#8	WL_066	78434	0	10062	0.128286
#8	WL_067	78434	0	47940	0.611215
#8	WL_069	78434	0	38260	0.487799
#8	WL_070	78434	0	21188	0.270138
#8	WL_071	78434	0	16692	0.212816
#8	WL_072	78434	0	46347	0.590904
#8	WL_076	78434	0	78178	0.996736
#8	WL_077	78434	0	55193	0.703687
#8	WL_078	78434	0	54400	0.693577
#8	WL_079	78434	0	19457	0.248068
#8	WL_080	78434	0	30076	0.383456
#8	WL_081	78434	0	30334	0.386746
#8 
#8 You can see that some individuals have as high as 99.6% missing data.  We definitely want to filter those out.  Let's take a look at a histogram
#c#9	$mawk '!/IN/' out.imiss | cut -f5 > totalmissing
#c#9	$gnuplot << \EOF 
#c#9	$set terminal dumb size 120, 30
#c#9	$set autoscale 
#c#9	$unset label
#c#9	$set title "Histogram of % missing data per individual"
#c#9	$set ylabel "Number of Occurrences"
#c#9	$set xlabel "% of missing data"
#c#9	$#set yr [0:100000]
#c#9	$binwidth=0.01
#c#9	$bin(x,width)=width*floor(x/width) + binwidth/2.0
#c#9	$plot 'totalmissing' using (bin($1,binwidth)):(1.0) smooth freq with boxes
#c#9	$pause -1
#c#9	$EOF
#9	
#9                                         Histogram of % missing data per individual
#9  Number of Occurrences
#9      3 ++----------+---------***---------***-----------+------------+-----------+-----------+-----------+----------++
#9        +           +         * *         * *           +       'totalmissing' using (bin($1,binwidth)):(1.0) ****** +
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9    2.5 ++                    * *         * *                                                                       ++
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9        |                     * *         * *                                                                        |
#9      2 ++   ***************  * ****      * *                                                                       ++
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9    1.5 ++   *    *  * **  *  * ** *      * *                                                                       ++
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        |    *    *  * **  *  * ** *      * *                                                                        |
#9        +    *    * +* **  *  * ** *      * *           +            +           +           +           +           +
#9      1 +*************************************************************************************************************
#9       0.1         0.2         0.3         0.4         0.5          0.6         0.7         0.8         0.9          1
#9                                                      % of missing data
#9
#9	Most of the individuals have less than 0.5 missing data.  That is probably a good cutoff to use for the moment.
#10
#10	Now we need to create a list of individuals with more than 50% missing data.  Anyone have any ideas?
#10
#10
#10	We can use mawk to do it.
#c#10	$mawk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv
#10	Who can explain what this is doing?
#11
#11	Now that we have a list of individuals to remove, we can feed that directly into VCFtools for filtering.
#c#11	$vcftools --vcf raw.g5mac3dp3.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out raw.g5mac3dplm
#11	As you can see from the output, this removed 9 individuals.  
#12
#12	I've included a script called filter_missing_ind.sh that will automate this process for you in the future.  Try it out.
#c#12	$curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/filter_missing_ind.sh
#c#12	$chmod +x filter_missing_ind.sh
#c#12	$filter_missing_ind.sh raw.g5mac3dp3.recode.vcf DP3g95maf05
#12	The command always follows the structure of filter_missing_ind.sh vcf_to_filter name_prefix_for_new_vcf
#12	The script prints out a histogram like the one above and also calculates the 85% for missing data.
#13	Now that we have removed poor coverage individuals, we can restrict the data to variants called in a high percentage of individuals and filter by mean depth of genotypes
#c#13	$vcftools --vcf raw.g5mac3dplm.recode.vcf --geno 0.95 --maf 0.05 --recode --recode-INFO-all --out DP3g95maf05 --min-meanDP 20
#13	This leaves us with about 12,754 loci in our filtered vcf file.
#14
#14	This applied a genotype call rate (95%) across all individuals.  With two localities, this is sufficient, but when you have multiple localities being sampled
#14	You are also going to want to filter by a population specific call rate.  VCFtools won't calculate this directly, but it is an easy workaround.
#14	First we need a file to define localities (populations).  Most programs want the file to have two tab separated columns.  First with the sample name, second with population assignment.
#14	I've already made one for this exercise.
#c#14	$cat popmap
#14	
#14	BR_002	BR
#14	BR_004	BR
#14	BR_006	BR
#14	BR_009	BR
#14	BR_013	BR
#14	BR_015	BR
#14	BR_016	BR
#14	BR_021	BR
#14	BR_023	BR
#14	BR_024	BR
#14	BR_025	BR
#14	BR_028	BR
#14	BR_030	BR
#14	BR_031	BR
#14	BR_040	BR
#14	BR_041	BR
#14	BR_043	BR
#14	BR_046	BR
#14	BR_047	BR
#14	BR_048	BR
#14	WL_031	WL
#14	WL_032	WL
#14	WL_054	WL
#14	WL_056	WL
#14	WL_057	WL
#14	WL_058	WL
#14	WL_061	WL
#14	WL_064	WL
#14	WL_066	WL
#14	WL_067	WL
#14	WL_069	WL
#14	WL_070	WL
#14	WL_071	WL
#14	WL_072	WL
#14	WL_076	WL
#14	WL_077	WL
#14	WL_078	WL
#14	WL_079	WL
#14	WL_080	WL
#14	WL_081	WL
#15 Now we need to create two lists that have just the individual names for each population
#c#15	$mawk '$2 == "BR"' popmap > 1.keep && mawk '$2 == "WL"' popmap > 2.keep
#15	The above line demonstrates the use of && to simultaneous execute two tasks.
#16
#16	Next, we use VCFtools to estimate missing data for loci in each population
#c#16	$vcftools --vcf DP3g95maf05.recode.vcf --keep 1.keep --missing --out 1
#c#16	$vcftools --vcf DP3g95maf05.recode.vcf --keep 2.keep --missing --out 2 
#16	This will generate files named 1.lmiss and 2.lmiss
#17	
#17	They follow this format
#c#17	$head -3 1.lmiss
#17	CHR		POS	N_DATA	N_GENOTYPE_FILTERED	N_MISS	F_MISS
#17	E1_L101	9	34		0					0		0
#17	E1_L101	15	34		0					0		0
#17
#17	I added extra tabs to make this easier to read, but what we are interested in is that last column with is the percentage of missing data for that locus.
#18	We can combine the two files and make a list of loci about the threshold of 10% missing data to remove.  Note this is double the overall rate of missing data.
#c#18	$cat 1.lmiss 2.lmiss | mawk '!/CHROM/' | mawk '$6 > 0.1' | cut -f1,2 >> badloci
#18	Who can walk us through that line of code?
#19
#19	We then feed this file back into VCFtools to remove any of the loci
#c#19	$vcftools --vcf DP3g95maf05.recode.vcf --exclude-positions badloci --recode --recode-INFO-all --out DP3g95p5maf05
#19	Again, we only had two populations so our overall filter caught all of these.  However, this will not be the case in multi-locality studies
#19	I also have made a script to automate this process as well.  It's called pop_missing_filter.sh
#20	Executing it with no parameters will give you the usage.
#c#20	$curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/pop_missing_filter.sh
#c#20	$chmod +x pop_missing_filter.sh
#c#20	$pop_missing_filter.sh
#20	Usage is pop_missing_filter vcffile popmap percent_missing_per_pop number_of_pops_for_cutoff name_for_output
#21
#21	From this point forward, the filtering steps assume that the vcf file was generated by FreeBayes.  
#21	Note that other SNP callers can be configured to include the similar annotations.
#21
#21	FreeBayes outputs a lot of information about a locus in the VCF file, using this information and the properties of RADseq, we add some sophisticated filters to the data.
#21	Let's take a look at the header of our VCF file and take a quick look at all the information.  
#c#21	$mawk '/#/' DP3g95maf05.recode.vcf
#21	This will output several lines of INFO tags, I have highlighted a few below:
#21	##INFO=<ID=NS,Number=1,Type=Integer,Description="Number of samples with data">
#21	##INFO=<ID=DP,Number=1,Type=Integer,Description="Total read depth at the locus">
#21	INFO=<ID=QR,Number=1,Type=Integer,Description="Reference allele quality sum in phred">
#21	##INFO=<ID=QA,Number=A,Type=Integer,Description="Alternate allele quality sum in phred">
#21	##INFO=<ID=SRF,Number=1,Type=Integer,Description="Number of reference observations on the forward strand">
#21	##INFO=<ID=SRR,Number=1,Type=Integer,Description="Number of reference observations on the reverse strand">
#21	##INFO=<ID=SAF,Number=A,Type=Integer,Description="Number of alternate observations on the forward strand">
#21	##INFO=<ID=SAR,Number=A,Type=Integer,Description="Number of alternate observations on the reverse strand">
#21	##INFO=<ID=AB,Number=A,Type=Float,Description="Allele balance at heterozygous sites: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous">
#21	##INFO=<ID=TYPE,Number=A,Type=String,Description="The type of allele, either snp, mnp, ins, del, or complex.">
#21	##INFO=<ID=CIGAR,Number=A,Type=String,Description="The extended CIGAR representation of each alternate allele, with the exception that '=' is replaced by 'M' to ease VCF parsing.  Note that INDEL alleles do not have the first matched base (which is provided by default, per the spec) referred to by the CIGAR.">
#21	##INFO=<ID=MQM,Number=A,Type=Float,Description="Mean mapping quality of observed alternate alleles">
#21	##INFO=<ID=MQMR,Number=1,Type=Float,Description="Mean mapping quality of observed reference alleles">
#21	##INFO=<ID=PAIRED,Number=A,Type=Float,Description="Proportion of observed alternate alleles which are supported by properly paired read fragments">
#21	##INFO=<ID=PAIREDR,Number=1,Type=Float,Description="Proportion of observed reference alleles which are supported by properly paired read fragments">
#21	##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">
#21	##FORMAT=<ID=GQ,Number=1,Type=Float,Description="Genotype Quality, the Phred-scaled marginal (or unconditional) probability of the called genotype">
#21	##FORMAT=<ID=GL,Number=G,Type=Float,Description="Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy">
#21	##FORMAT=<ID=DP,Number=1,Type=Integer,Description="Read Depth">
#21	##FORMAT=<ID=RO,Number=1,Type=Integer,Description="Reference allele observation count">
#21	##FORMAT=<ID=QR,Number=1,Type=Integer,Description="Sum of quality of the reference observations">
#21	##FORMAT=<ID=AO,Number=A,Type=Integer,Description="Alternate allele observation count">
#21	##FORMAT=<ID=QA,Number=A,Type=Integer,Description="Sum of quality of the alternate observations">
#22
#22	The first filter we will apply will be on allele balance.  Allele balance is:
#22	a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous
#22	Because RADseq targets specific locations of the genome, we expect that the allele balance in our data (for real loci) should be close to 0.5
#22	We can use the vcffilter program from vcflib.  (https://github.com/ekg/vcflib)
#22	Typing it with no parameters will give you the usage.
#c#22	$vcffilter
#22	usage: vcffilter [options] <vcf file>
#22	
#22	options:
#22	    -f, --info-filter     specifies a filter to apply to the info fields of records,
#22	                          removes alleles which do not pass the filter
#22	    -g, --genotype-filter specifies a filter to apply to the genotype fields of records
#22	    -k, --keep-info       used in conjunction with '-g', keeps variant info, but removes genotype
#22	    -s, --filter-sites    filter entire records, not just alleles
#22	    -t, --tag-pass        tag vcf records as positively filtered with this tag, print all records
#22	    -F, --tag-fail        tag vcf records as negatively filtered with this tag, print all records
#22	    -A, --append-filter   append the existing filter tag, don't just replace it
#22	    -a, --allele-tag      apply -t on a per-allele basis.  adds or sets the corresponding INFO field tag
#22	    -v, --invert          inverts the filter, e.g. grep -v
#22	    -o, --or              use logical OR instead of AND to combine filters
#22	    -r, --region          specify a region on which to target the filtering, requires a BGZF
#22	                          compressed file which has been indexed with tabix.  any number of
#22	                          regions may be specified.
#23	
#23	Let's use our first filter
#c#23	$vcffilter -s -f "AB > 0.25 & AB < 0.75 | AB < 0.01" DP3g95p5maf05.recode.vcf > DP3g95p5maf05.fil1.vcf
#23	vcffilter works with simple conditional statements, so this filters out loci with an allele balance below 0.25 and above 0.75.  However, it does include those that are close to zero.
#23	The last condition is to catch loci that are fixed variants (all individuals are homozygous for one of the two variants).
#23	The -s tells the filter to apply to sites, not just alleles
#24	To see how many loci are now in the VCF file, you could feed it into VCFtools or you can just use a simple mawk statement
#c#24	$mawk '!/#/' DP3g95p5maf05.recode.vcf | wc -l
#24	12754
#c#24	$mawk '!/#/' DP3g95p5maf05.fil1.vcf | wc -l
#24	9678
#24	You'll notice that we've filtered a lot of loci.  In my experience though, I find that most of these tend to be errors of some kind.
#24	However, this will be data dependent.  I encourage you to explore your own data sets.  
#25	
#25	The next filter we will apply filters out sites that have reads from both strands.  For GWAS and even RNAseq, this can be a good thing.  
#25	Unless you are using super small genomic fragment or really long reads (MiSeq).  A SNP should be covered only by forward or only reverse reads.
#c#25	$vcffilter -f "SAF / SAR > 100 & SRF / SRR > 100 | SAR / SAF > 100 & SRR / SRF > 100" -s DP3g95p5maf05.fil1.vcf > DP3g95p5maf05.fil2.vcf
#25	The filter is based on proportions, so that a few extraneous reads won't remove an entire locus.  In plain english, it's keeping loci that have over 100 times
#25	more  forward alternate reads than reverse alternate reads and 100 times more forward reference reads than reverse reference reads along with the reciprocal.  
#26
#c#26	$mawk '!/#/' DP3g95p5maf05.fil2.vcf | wc -l
#26	9491
#26	That only removes a small proportion of loci, but these loci are likely to be paralogs, microbe contamination, or weird PCR chimeras.
#27	
#27	The program SAMtools is a great way to visualize alignments right from the terminal.
#27
#c#27	$samtools tview BR_006-RG.bam reference.fasta -p E28188_L151
#27	
#27	         11        21        31        41        51        61        71        81        91        101       111       121	 131
#27	AATTCTCAGAGCTAGAGTGGGGACGGCAGTTGGTAGAGGGTACAGCAGTTCTAAAAACATGTAGAAATTTTCTCTTCAACTCGCTCCTACGGCCACAGCGTTCACTCCACATACACAAATTGTACACCAAAACATAGGAAAAG
#27	...........S...........Y.K......S.........G.......K.........S............................Y........Y....W.........................M...G.........
#27	..........................................G.......G......................................T.....
#27	..........................................G.......T............................................
#27	...........G...........T.T......C.........G.................C...............................
#27	..........................................G.......T....................................G.......
#27	..........................................G.......T............................................
#27	...........G...........T.T......C.........G.................C..................................
#27	..........................................G.......T............................................
#27	...........G.................C............G.......G.................******........A...............T..
#27	                                            ,,,,,,g,,,,,,,,,,,,,,,,,******,,,,,,,,a,,,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,
#27	                                                  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,g,,,,,,,,,
#27	                                                  t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  ,,,,,,,,,,c,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,
#27	                                                  g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,
#27	                                                  g,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,g,,,,,,,,,
#27	                                                  ,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,g,,,,,,,,,
#27	                                                  t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,a,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  ,,,,,,,,,,c,g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,
#27	                                                  g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  g,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27	                                                  g,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,t,,,,,,,,,,,,,t,,,,,,,,,,,,,,,,,,,,,,,,,c,,,g,,,,,,,,,
#27
#27	As you can see this is a mess.  There appear to be  over two haplotypes here.  
#27	For more info on how to use samtools tview press the question mark while you are in the window.
#28	
#28	The next filter looks at the ratio of mapping qualities between reference and alternate alleles
#c#28	$vcffilter -f "MQM / MQMR > 0.9 & MQM / MQMR < 1.05" DP3g95p5maf05.fil2.vcf > DP3g95p5maf05.fil3.vcf
#28	The rationale here is that, again, because RADseq loci and alleles all should start from the same genomic location there should not be large discrepancy
#28	between the mapping qualities of two alleles. 
#c#29	$mawk '!/#/' DP3g95p5maf05.fil3.vcf | wc -l
#29	9229 
#29	This filters away less than 3% of the variants, but likely need to be filtered.  Let's take a look at one
#c#30	$samtools tview BR_004-RG.bam reference.fasta -p E20_L173
#30	1         11        21        31        41        51        61        71        81        91        101       111	121	  131
#30	NAATTCATCTGTTGCAGGCAGCTCACACTTGCAGCCTCGGCTCGCACCAGCAGAGCAGCCGTAGAATACTTAGTTTAATAGAATGGCTTGGCATTTNNNNNNNNNNCATGAGGTTGTTATTCTCAGAAGACTAATCACAGACA
#30	 .......Y.........YM....WS...Y....S...R....R....................................................C         ....................G................
#30	 .......T.........TC....TG...C....G...A....A..................................                            ,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,,,,,,,
#30	 .......T.........TC.....G...C....G...A....A..................................                            ,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,,,,,,,
#30	 .......T.........TC....TG...C....G...A....A..................................                            ,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,,,,,,,
#30	 .......T.........TC.....G...C....G...A....A..................................                            ,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,,,,,,,
#30	 .......T.........TC.....G...C....G...A....A..................................                            ,,,,,,,,,,,,,,,,,,,,g,,,,,,,,,,,,,,,,
#30	 .......T.........TC....TG...C....G...A....A..................................
#30	 .......T.........TC.....G...C....G...A....A..................................
#30	 .......T.........TC.....G...C....G...A....A..................................
#30	 .......T.........TC....TG...C....G...A....A..................................
#30	 .......T.........TC....TG...C....G...A....A..................................
#30	 ..........C....................................................................................C
#30	 .......T.........TC.....G...C....G...A....A..................................
#30	 ..........C....................................................................................C
#30	 .......T.........TC.....G...C....G...A....A..................................
#30	 ......GT.........TC.....G...C....G...A....A..................................
#30	 .......T.........TC....TG...C....G...A....A..................................
#30
#30	There is a large amount of clipping going on here for the variant alleles likely why the mapping quality is low for them.  You can also see
#30	that there are three different alleles present here.  Press SHIFT+L to scroll further down the alignment.  You can see that some of the polymorphism
#30	is also link to a cut site variant.  All things that should be avoided.
#31
#31	Yet another filter that can be applied is whether or not their is a discrepancy in the properly paired status of for reads supporting reference or alternate alleles.
#c#31	$vcffilter -f "PAIRED > 0.05 & PAIREDR > 0.05 & PAIREDR / PAIRED < 1.75 & PAIREDR / PAIRED > 0.25 | PAIRED < 0.05 & PAIREDR < 0.05" -s DP3g95p5maf05.fil3.vcf > DP3g95p5maf05.fil4.vcf
#31	Since de novo assembly is not perfect, some loci will only have unpaired reads mapping to them.  This is not a problem.  The problem occurs when all the reads supporting the reference allele
#31	are paired but not supporting the alternate allele.  That is indicative of a problem.
#c#32	$mawk '!/#/' DP3g95p5maf05.fil4.vcf | wc -l
#32	9166
#32 Our loci count keeps dwindling, but our signal to noise ration keeps increasing.  Let's look at an example of what we filtered.
#c#33	$samtools tview BR_006-RG.bam reference.fasta -p E4407_L138
#33	This output doesn't paste well to the terminal, but you can see the clear discrepancy between mapping status and allele status.  This could be indicative of cut site polymorphism or paralogs.
#34	The next filter we will apply is to look at the ration of locus quality score to depth
#34	Heng Li found some interesting results about how quality score and locus depth are related to each other in real and spurious variant calls
#34	See his preprint here (http://arxiv.org/pdf/1404.0929.pdf)
#34	Also see this great blog post about it here (http://bcb.io/2014/05/12/wgs-trio-variant-evaluation/)  I REALLY REALLY recommend following that blog.  Brad Chapman's group is really good.
#34	In short, with whole genome samples, it was found that high coverage can lead to inflated locus quality scores.  Heng proposed that for read depths greater than the mean depth plus 2-3 times 
#34 the square root of mean depth that the quality score will be twice as large as the depth in real variants and below that value for false variants.  
#34	I actually found that this is a little too conservative for RADseq data, likely because the reads aren't randomly distributed across contigs.  I implement two filters based on this idea.
#34 the first is removing any locus that has a quality score below 1/4 of the depth.
#c#34	$vcffilter -f "QUAL / DP > 0.25" DP3g95p5maf05.fil4.vcf > DP3g95p5maf05.fil5.vcf
#35	The second is more complicated.  The first step is to create a list of the depth of each locus
#c#35	$cut -f8 DP3g95p5maf05.fil5.vcf | grep -oe "DP=[0-9]*" | sed -s 's/DP=//g' > DP3g95p5maf05.fil5.DEPTH
#35	Who can talk us through this line of code?
#36	The second step is to create a list of quality scores.
#c#36	$mawk '!/#/' DP3g95p5maf05.fil5.vcf | cut -f1,2,6 > DP3g95p5maf05.fil5.vcf.loci.qual
#37	Next step is to calculate the mean depth 
#c#37	$mawk '{ sum += $1; n++ } END { if (n > 0) print sum / n; }' DP3g95p5maf05.fil5.DEPTH
#37	1952.82
#38	Now the the mean plus 3X the square of the mean
#c#38	$python -c "print int(1952+3*(1952**0.5))"
#38	2084
#39	Next we paste the depth and quality files together and find the loci above the cutoff that do not have quality scores 2 times the depth
#c#39	$paste DP3g95p5maf05.fil5.vcf.loci.qual DP3g95p5maf05.fil5.DEPTH | mawk -v x=2084 '$4 > x' | mawk '$3 < 2 * $4' > DP3g95p5maf05.fil5.lowQDloci
#40	Now we can remove those sites and recalculate the depth across loci with VCFtools
#c#40	$vcftools --vcf DP3g95p5maf05.fil5.vcf --site-depth --exclude-positions DP3g95p5maf05.fil5.lowQDloci --out DP3g95p5maf05.fil5
#41
#41	Now let's take VCFtools output and cut it to only the depth scores
#c#41	$cut -f3 DP3g95p5maf05.fil5.ldepth > DP3g95p5maf05.fil5.site.depth
#42
#42	Now let's calculate the average depth by dividing the above file by the number of individuals 31
#c#42	$mawk '!/D/' DP3g95p5maf05.fil5.site.depth | mawk -v x=31 '{print $1/x}' > meandepthpersite
#43	Let's plot the data as a histogram
#c#43	$gnuplot << \EOF 
#c#43	$set terminal dumb size 120, 30
#c#43	$set autoscale
#c#43	$set xrange [10:150] 
#c#43	$unset label
#c#43	$set title "Histogram of mean depth per site"
#c#43	$set ylabel "Number of Occurrences"
#c#43	$set xlabel "Mean Depth"
#c#43	$binwidth=1
#c#43	$bin(x,width)=width*floor(x/width) + binwidth/2.0
#c#43	$set xtics 5
#c#43	$plot 'meandepthpersite' using (bin($1,binwidth)):(1.0) smooth freq with boxes
#c#43	pause -1
#c#43	EOF
#43	
#43	                                              Histogram of mean depth per site
#43	  Number of Occurrences
#43	    250 ++--+---+---+---+--+---+---+---+---+---+---+---+---+---+--+---+---+---+---+---+---+---+---+--+---+---+---+--++
#43	        +   +   +   +   +  +   +   +   +   +   +   +   +   +'meandepthpersite' using (bin($1,binwidth)):(1.0)+****** +
#43	        |               **    **                                                                                     |
#43	        |               ***   **                                                                                     |
#43	        |               ********                                                                                     |
#43	    200 ++              ********* *                                                                                 ++
#43	        |           ** ********** *                                                                                  |
#43	        |           ************* **  *                                                                              |
#43	        |           ****************  *  *                                                                           |
#43	        |           *******************  **                                                                          |
#43	    150 ++          ******************* ***                                                                         ++
#43	        |           *************************                                                                        |
#43	        |           ***************************                                                                      |
#43	        |       *******************************                                                                      |
#43	    100 ++      **********************************                                                                  ++
#43	        |       **********************************                                                                   |
#43	        |       ************************************** *                                                             |
#43	        |       ************************************** * **                                                          |
#43	        |       *********************************************                                                        |
#43	     50 ++      ************************************************                                                    ++
#43	        |       ************************************************   **   **                                           |
#43	        |       ***********************************************************  **                                      |
#43	        |       ****************************************************************  **  **                 **          |
#43	        +   +   ************************************************************************************** ******+********
#43	      0 ++--+---******************************************************************************************************
#43	        10  15  20  25  30 35  40  45  50  55  60  65  70  75  80 85  90  95 100 105 110 115 120 125130 135 140 145 150
#43                                                         Mean Depth
#43
#44	Loci that have high mean depth are indicative of either paralogs or multicopy loci.  Either way we want to remove them.  Here, I'd 
#44	remove all loci above a mean depth of 102.5.  Now we can combine both filters to produce another VCF file
#c#44	$vcftools --vcf  DP3g95p5maf05.fil5.vcf --recode-INFO-all --out DP3g95p5maf05.FIL --max-meanDP 102.5 --exclude-positions DP3g95p5maf05.fil5.lowQDloci --recode 
#44	In the end, VCFtools kept 8417 out of a possible 9164 Sites.
#44	BTW, I've also written a script to automate the filterings steps described in steps 23-44.  It's called dDocent_filters.  It will go through the filtering steps and
#44	recode a log file for you for each of the steps, including the depth histogram. 
#c#44	$curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/dDocent_filters
#c#44	$chmod +x dDocent_filters
#45
#45	The next filter to apply is HWE.  Heng Li also found that HWE is another excellent filter to remove erroneous variant calls.
#45	We don't want to apply it across the board, since population structure will create departures from HWE as well.  We need to apply this by population.
#45 I've included a perl script written by Chris Hollenbeck, one of the PhD student's in my current lab that will do this for us.
#c#45	$curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/filter_hwe_by_pop.pl
#c#45	$chmod +x filter_hwe_by_pop.pl
#c#45	$filter_hwe_by_pop.pl
#45 Usage:
#45     filter_hwe_by_pop.pl -v <vcffile> -p <popmap> [options]
#45 
#45     Options: -v <vcffile> input vcf file -p <popmap> tab-separated file of
#45     samples and population designations -h [hwe] minimum Hardy-Weinberg
#45     p-value cutoff for SNPs -c [cutoff] proportion of all populations that a
#45     locus can be below HWE cutoff without being filtered -o [out] name of
#45     outfile
#45 
#45 Options:
#45     -v, --vcffile
#45             VCF input file
#45 
#45     -p, --popmap
#45             File with names of individuals and population designations, one
#45             per line
#45 
#45     -h, --hwe
#45             Minimum cutoff for Hardy-Weinberg p-value (for test as
#45             implemented in vcftools) [Default: 0.001]
#45 
#45     -c, --cutoff
#45             Proportion of all populations that a locus can be below HWE
#45             cutoff without being filtered. For example, choosing 0.5 will
#45             filter SNPs that are below the p-value threshold in 50% or more
#45             of the populations. [Default: 0.25]
#45 
#45     -o, --out
#45             Name of outfile, by vcftools conventions (will be named
#45             X.recode.vcf)
#46	Let's filter our SNPs by population specific HWE
#c#46	$filter_hwe_by_pop.pl -v DP3g95p5maf05.FIL.recode.vcf -p popmap -o DP3g95p5maf05.HWE -h 0.01
#46	Processing population: 1 (20 inds)
#46	Processing population: 2 (20 inds)
#46	Outputting results of HWE test for filtered loci to 'filtered.hwe'
#46	Kept 8232 of a possible 8417 loci (filtered 185 loci)
#47	Note that I would not normally filter with that high of a -h value.  It's purely for this example. 
#47	Typically, errors would have a low p-vaule and would be present in many populations.
#47	We have now created a thoroughly filtered VCF.  There's not much more we can do with it in this format.  To filter further, we need to convert the file to SNPs only.
#48	To do this we will use another command from vcflib called vcfallelicprimatives
#c#48	$vcfallelicprimitives DP3g95p5maf05.HWE.recode.vcf --keep-info --keep-geno > DP3g95p5maf05.HWE.prim.vcf
#48	This will decompose complex variant calls into phased SNP and INDEL genotypes and keep the INFO flags for loci and genotypes.
#49	Next, we can feed this VCF file into VCFtools to remove indels.
#c#49	$vcftools --vcf DP3g95p5maf05.HWE.prim.vcf --remove-indels --recode --recode-INFO-all --out SNP.DP3g95p5maf05.HWE
#49	We now have 8179 SNP calls in our new VCF.
#50	That's a lot of filtering, and we should have confidence in these SNP calls.  
#50	However, our lab is currently developing one more script, called rad_haplotyper.  
#50	This tool takes a VCF file of SNPs and will parse through BAM files looking to link SNPs into haplotypes along paired reads.
#c#50	$curl -L -O https://github.com/chollenbeck/rad_haplotyper/raw/master/rad_haplotyper.pl
#c#50	$chmod +x rad_haplotyper.pl
#50	Note, this script requires several Perl libraries.  See the README at https://github.com/chollenbeck/rad_haplotyper
#50	It has a lot of options, let's take a look
#c#50	$rad_haplotyper.pl
#50	Usage:
#50	    perl rad_haplotyper.pl -v <vcffile> -r <reference> [options]
#50	
#50	    Options: -v <vcffile> input vcf file
#50	
#50	             -r     <reference>             reference genome
#50	         
#50	             -s     [samples]               optionally specify an individual sample to be haplotyped
#50	         
#50	             -u     [snp_cutoff]            remove loci with more than a specified number of SNPs
#50	         
#50	             -h     [hap_cutoff]            remove loci with more than a specified number of haplotypes relative to SNPs
#50	         
#50	             -m     [miss_cutoff]           cutoff for proportion of missing data for loci to be included in the output
#50	         
#50	             -mp    [max_paralog_inds]              cutoff for excluding possible paralogs
#50	         
#50	             -ml    [max_low_cov_inds]              cutoff for excluding loci with low coverage or genotyping errors
#50	         
#50	             -d     [depth]                 sampling depth used by the algorithm to build haplotypes
#50	         
#50	             -g     [genepop]               genepop file for population output
#50	         
#50	             -p     [popmap]                population map for organizing Genepop file
#50	         
#50	             -t     [tsvfile]               tsv file for linkage map output
#50	         
#50	             -a     [imafile]               IMa file output
#50	         
#50	             -p1    [parent1]               first parent in the mapping cross
#50	         
#50	             -p2    [parent2]               second parent in the mapping cross
#50	         
#50	             -x     [threads]               number of threads to use for the analysis
#50	         
#50	             -n                             use indels
#50	         
#50	             -e                             debug
#50	
#50	Options:
#50	    -v, --vcffile
#50	            VCF input file
#50	
#50	    -r, --reference
#50	            Reference genome (FASTA format)
#50	
#50	    -s, --samples
#50	            Individual samples to use in the analysis - can be used multiple
#50	            times for multiple individuals [Default: All]
#50	
#50	    -u, --cutoff
#50	            Excludes loci with more than the specified number of SNPs
#50	            [Default: No filter]
#50	
#50	    -h, --hap_count
#50	            Excludes loci with more than the specified number of haplotypes
#50	            relative to number of SNPs. Excluding forces other than mutation
#50	            (i.e. recombination) the maximum number of haplotypes should be
#50	            one more than the number of SNPs at the locus. The value
#50	            provided is the number of haplotypes allowed in excess of the
#50	            number of SNPs, which allows that mechanisms other than mutation
#50	            may have influenced the number of haplotypes in the population.
#50	            [Default: 100]
#50	
#50	    -x, --threads
#50	            Run in parallel across individuals with a specified number of
#50	            threads
#50	
#50	    -n, --indels
#50	            Includes indels that are the only polymorphism at the locus
#50	            (tag)
#50	
#50	    -d, --depth
#50	            Specify a depth of sampling reads for building haplotypes
#50	            [Default: 20]
#50	
#50	    -m, --miss_cutoff
#50	            Proportion of missing data cutoff for removing loci from the
#50	            final output. For example, to keep only loci with successful
#50	            haplotype builds in 95% of individuals, enter 0.95. [Default:
#50	            0.9]
#50	
#50	    -mp, --max_paralog_inds
#50	            Count cutoff for removing loci that are possible paralogs from
#50	            the final output. The value is the maximum allowable number of
#50	            individuals with more than the expected number of haplotypes
#50	            [Default: No filter]
#50	
#50	    -ml, --max_low_cov_inds
#50	            Count cutoff for removing loci with low coverage or genotyping
#50	            errors from the final output. The value is the maximum allowable
#50	            number of individuals with less than the expected number of
#50	            haplotypes [Default: No filter]
#50	
#50	    -g, --genepop
#50	            Writes a genepop file using haplotypes. Must provide the name of
#50	            the genepop file.
#50	
#50	    -a, --ima
#50	            Writes a IMa file using haplotypes. Must provide the name of the
#50	            IMa file.
#50	
#50	    -p, --popmap
#50	            Tab-separated file of individuals and their population
#50	            designation, one per line (required for Genepop output)
#50	
#50	    -t, --tsvfile
#50	            Writes a tsv file using haplotypes - for mapping crosses only.
#50	            Must provide the name of the tsv file.
#50	
#50	    -p1, --parent1
#50	            Parent 1 of the mapping cross (must be specified if writing a
#50	            tsv file)
#50	
#50	    -p2, --parent2
#50	            Parent 2 of the mapping cross (must be specified if writing a
#50	            tsv file)
#50	
#50	    -e, --debug
#50	            Output extra logs for debugging purposes
#50
#51 We don't have enough time to go into depth with all these options and this tool is still under development.  
#51	It also take some substantial resources to run. I will simulate running this for you.
#c#51	$#rad_haplotyper.pl -v SNP.DP3g95p5maf05.HWE.recode.vcf -x 40 -mp 1 -u 20 -ml 4 -n -r reference.fasta
#51	Note, this will not actually run.  It needs all the BAM files to proceed.
#51	
#51	Removed 0 loci (0 SNPs) with more than 20 SNPs at a locus
#51	Building haplotypes for BR_024
#51	Building haplotypes for BR_028
#51	Building haplotypes for WL_054
#51	Building haplotypes for BR_016
#51	Building haplotypes for BR_009
#51	Building haplotypes for BR_006
#51	Building haplotypes for BR_041
#51	Building haplotypes for BR_040
#51	Building haplotypes for BR_046
#51	Building haplotypes for BR_031
#51	Building haplotypes for BR_025
#51	Building haplotypes for BR_002
#51	Building haplotypes for WL_058
#51	Building haplotypes for WL_057
#51	Building haplotypes for WL_061
#51	Building haplotypes for WL_069
#51	Building haplotypes for WL_070
#51	Building haplotypes for BR_048
#51	Building haplotypes for WL_031
#51	Building haplotypes for WL_056
#51	Building haplotypes for BR_047
#51	Building haplotypes for WL_079
#51	Building haplotypes for WL_080
#51	Building haplotypes for WL_032
#51	Building haplotypes for WL_071
#51	Building haplotypes for WL_081
#51	Building haplotypes for BR_004
#51	Building haplotypes for BR_021
#51	Building haplotypes for BR_015
#51	Building haplotypes for BR_043
#51	Building haplotypes for WL_066
#51	Filtered 26 loci below missing data cutoff
#51	Filtered 66 possible paralogs
#51	Filtered 17 loci with low coverage or genotyping errors
#51	Filtered 0 loci with an excess of haplotypes
#52
#52	The script found another 109 loci to remove from our file.  Besides this output to the terminal, the script outputs a file called stats.out
#52	Let's symlink that file to our current directory.
#c#52	$head stats.out
#52		
#52	Locus		Sites	Haplotypes	Inds_Haplotyped	Total_Inds	Prop_Haplotyped	Status	Poss_Paralog	Low_Cov/Geno_Err	Miss_Geno	Comment
#52	E10001_L101	1		2			30				31			0.968			PASSED	0				0					1	
#52	E10003_L101	7		9			30				31			0.968			PASSED	1				0					0	
#52	E10004_L101	-		-			-				-			-				FILTERED0				0					1			Complex
#52	E10008_L101	1		2			30				31			0.968			PASSED	0				0					1	
#52	E10013_L142	3		6			30				31			0.968			PASSED	0				0					1	
#52	E10014_L117	2		3			31				31			1.000			PASSED	0				0					0	
#52	E10024_L101	1		2			31				31			1.000			PASSED	0				0					0	
#52	E10029_L101	1		2			31				31			1.000			PASSED	0				0					0	
#53	
#53	We can use this file to create a list of loci to filter
#c#53	$grep FILTERED stats.out | mawk '!/Complex/' | cut -f1 > loci.to.remove
#54	Now that we have the list we can parse through the VCF file and remove the bad RAD loci
#54	I've made a simple script to do this remove.bad.hap.loci.sh
#c#54	$curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/remove.bad.hap.loci.sh
#c#54	$chmod +x remove.bad.hap.loci.sh
#c#54	$remove.bad.hap.loci.sh loci.to.remove SNP.DP3g95p5maf05.HWE.recode.vcf 
#54	This produces a FINAL FINAL FINAL filtered VCF file	SNP.DP3g95p5maf05.HWE.filtered.vcf
#c#55	$mawk '!/#/' SNP.DP3g95p5maf05.HWE.filtered.vcf | wc -l
#55	We're left with 8,179 SNPs!
#56	How man possible errors?
#c#56	$ErrorCount.sh SNP.DP3g95p5maf05.HWE.filtered.vcf
#56	Potential genotyping errors from genotypes from only 1 read range from 0 to 0.0
#56	Potential genotyping errors from genotypes from only 2 reads range from 0 to 0.0
#56	Potential genotyping errors from genotypes from only 3 reads range from 276 to 928.62
#56	Potential genotyping errors from genotypes from only 4 reads range from 152 to 772.304
#56	Potential genotyping errors from genotypes from only 5 reads range from 81 to 615
#56	31 number of individuals and 8179 equals 253549 total genotypes
#56	Total genotypes not counting missing data 252927
#56	Total potential error rate is between 0.00201243837155 and 0.00915649179407
#56	
#56	
#56	SCORCHED EARTH SCENARIO
#56	WHAT IF ALL LOW DEPTH HOMOZYGOTE GENOTYPES ARE ERRORS?????
#56	The total SCORCHED EARTH error rate is 0.0286723046571.
#57
#57	Congrats!  You've finished the Filtering Tutorial


#!/bin/bash
if which FilterTut &>/dev/null; then
    LOC=$(which FilterTut 2>/dev/null)
else
	LOC="./FilterTut"
fi
if [[ -z "$1" ]]; then
head -13 $LOC
else
PATTERN=#$1[[:blank:]]
grep "$PATTERN" $LOC | awk '{$1=""; print $0}'
fi
